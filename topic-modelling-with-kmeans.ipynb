{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling menggunakan LDA dengan klasifikasi KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "import pyLDAvis\n",
    "# import spacy\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "from gensim import corpora\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models import ldamodel, lsimodel\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    file = open(filename, 'r')\n",
    "\n",
    "    acc_names = []\n",
    "    tweets = []\n",
    "\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        parts = line.split('###')\n",
    "        acc_names.append(parts[0])\n",
    "        tweets.append(parts[1])\n",
    "\n",
    "    return acc_names, tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables\n",
    "num_topics=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definisikan beberapa fungsi untuk kebutuhkan pre-processing, pre-processing yang dilakukan adalah\n",
    "# 1. lowercasing\n",
    "# 2. stopword removal\n",
    "# 3. stemming\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def preprocess(text):\n",
    "\n",
    "    # tokenizing and lowercasing\n",
    "    tokens = [word.lower() for word in text.split()]\n",
    "    filtered_tokens = []\n",
    "\n",
    "    # buat yang bukan terdiri dari alfabet, dan merupakan stopword\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token) and (token not in stopwords):\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    # lakukan stemming dengan snowball stemmer\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita load dokumen twitter, dan lakukan preprocessing terhadap tweet yang sudah di-load\n",
    "acc_names, tweets = load_dataset(\"twitter.txt\")\n",
    "\n",
    "# Lakukan pre-process untuk setiap tweet pada koleksi \"tweets\" kita\n",
    "# Gunakan List Comprehension untuk mempermudah hidup kita\n",
    "tweets_label = tweets\n",
    "tweets = [preprocess(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['kardashian', 'yr', 'anniversary,', 'iphon', 'yr', 'anniversary,', 'so,', 'kardashian', 'made', 'iphon'], ['iphon', 'year', 'old.', 'appl', 'watch', 'year', 'old.', 'feel', 'peopl', 'forget', 'small', 'fact.'], [\"can't\", 'save', 'make,', 'live', 'beyond', 'means.', 'ditch', 'starbucks,', 'eat', 'less,', 'need', 'new', 'iphone,', 'save', 'money!'], ['time', 'year!', 'iphon', 'vs.', 'samsung', 'galaxi', 's8', 'smackdown:'], ['sell', 'yeezi', 'samsung', 'galaxi', 's8', 'anyon', 'interest', 'show', 'proof', 'trust', '@devilishrt', '@alienrt', '@bear_retweet', '@flyrt'], ['iphon', '16gb', 'spacegray', 'peso', 'only!', 'complet', 'full', 'packag', 'guys!', 'dm'], ['swear', 'even', 'iphon', 'dress', 'clown,', 'reach', 'pillow', '&choke', 'slept,', 'still', 'buy', 'samsung'], ['iphon', '8', 'a11', 'bionic', 'chip', 'lost', 'samsung', 'galaxi', 'note', 'app', 'launch', 'time', 'multitask', 'speeds.'], ['confus', 'post', 'dedic', 'camera', 'review', 'samsung', 'galaxi', 'note', 'includ', 'camera', 'section', 'main', 'full', 'review?'], ['guy', 'use', 'iphone6&', 'samsung', 'galaxi', 'sale..', 'plz', 'dm'], ['mom', 'say', 'devil', 'give', 'samsung,', 'take', 'iphon', 'return?'], ['cassi', 'iphon', 'could', 'open', 'lie', 'face!', '#60min'], ['infam', 'samsung', 'galaxi', 'note', 'still', 'ban', 'aircraft', 'even', 'got', 'prohibit', 'symbol'], ['so,', 'realli', 'dumb', 'phone.', 'samsung', 'galaxi', 'note', 'phone', 'great', 'mayb', 'year', 'ago,'], ['\"bro', 'window', 'delux', 'brick', 'trashcan', 'everyth', 'iphon', 'sheep', 'bro\"'], ['samsung', 'galaxi', 'note', 'camera:', 'blur', 'line', 'samsung', 'attempt', 'redempt', 'note', 'line', 'is,', 'part,'], ['iphon', 'x', 'look', 'lot', 'like', 'samsung', 'galaxi', 's10', 'plus'], ['congratulations.', 'news', 'iphon', 'jailbreak', 'bought', 'new', 'iphone.'], ['messi', 'arguabl', 'greatest', 'perform', 'major', 'final', 'champion', 'leagu', 'final)', 'ever.'], ['im', 'gonna', 'boo', 'gini', 'tomorrow,', 'alway', 'gonna', 'leav', 'man,', 'good', 'championship', 'champion', 'leagu', 'tabl', 'ffs...'], ['grayson', 'backtracking,', 'lost', 'me,', 'bruce', 'same.', 'mcgeadi', 'wrongun', 'celebration,', 'thought', \"we'd\", 'champion', 'league,p!ss', 'poor', '#safc'], ['chelsea', 'found', 'citi', 'atletico', 'madrid'], ['delph', 'idiot', 'leav', 'villa.', 'releg', 'battl', 'first', 'choic', 'player', 'champion', 'leagu', 'prem'], ['chelsea', 'taken', 'point', 'possibl', 'champion', 'leagu', 'fixtur'], ['zinedin', 'zidane:', '\"give', 'lord', 'fellaini', 'piec', 'wood', \"i'll\", 'win', 'champion', 'league,', 'world', 'cup', 'uefa', 'euro'], ['dj', 'play', 'champion', 'leagu', 'anthem', 'chic', 'caught', 'bouquet'], ['harri', 'kane', 'current', 'joint', 'top', 'scorer', 'premier', 'leagu', 'outright', 'top', 'scorer', 'champion', 'league.', 'elite.'], ['harri', 'kane', 'one', 'deserv', 'world-class', 'tag', 'despit', 'cut', 'intern', 'tournament', 'champion', 'leagu', '(yet).'], ['christensen:', 'face', 'striker', 'bundesliga', 'two', 'year', 'champion', 'leagu', 'well,', 'got', 'much', 'experience.', '[telegraph]'], ['sinc', 'premier', 'leagu', 'club', 'domin', 'champion', 'leagu', 'like', 'this.'], ['good', 'luck', 'arsenal', 'europa', 'leagu', 'game,', 'hope', 'next', 'season', 'get', 'play', 'champion', 'league.'], ['chelsea', 'display', 'best', 'english', 'club', 'champion', 'leagu', 'season.', 'win', 'away', 'atletico', 'mean', 'feat.', 'full', 'valu', 'too.'], ['brilliant', 'scottish', 'crew', 'support', 'catalan', 'referendum,', 'viva', 'catalunya'], ['brexit', 'support', 'support', 'catalunya', 'referendum', 'sovereignti', 'self', 'determin', 'nations.', 'si'], ['offici', 'referendum', 'day', 'babi', 'awooooo', '(wolf', 'howl)', 'catalunya', 'ride'], ['derri', 'wall', 'turn', 'yellow', 'red', 'solidar', 'catalonia', 'eve', 'independ', 'referendum.', 'viva', 'catalunya!'], ['watch', 'madrid', 'forc', 'polic', 'catalunya', 'prevent', 'referendum', 'unedifi', 'spectacle.', 'whimper', 'liber', 'protest'], ['catalan', 'referendum', 'full', 'flow', 'barcelona', 'ever', 'happens,', 'peac', 'love,', 'right?'], ['patriot', 'fervour', 'barcelona', 'ahead', 'referendum', 'catalunya', 'tomorrow'], ['tomorrow', '#indyref', 'referendum', '#catalunya.', 'whole', 'europ', 'watch', 'close'], ['controversi', 'referendum', 'due', 'stage', 'sunday,', 'catalunya', 'seek', 'becom', 'recognis', 'nation'], ['last', 'poll', 'catalan', 'independ', 'referendum.83%', 'yes!', 'inform', 'ban', 'catalunya.'], ['catalan', 'judg', 'sue', 'spanish', 'govt.', 'block', 'referendum'], ['thought', 'tri', 'get', '@thenat', 'articl', 'catalunya', 'referendum'], ['wikileak', 'mirror', 'censor', 'catalan', 'govern', 'referendum', 'site', 'includ', 'poll', 'station'], ['chao', 'catalonia:', 'spanish', 'offici', 'scrambl', 'stop', 'secess', 'referendum'], ['tast', 'atmosfer', 'referendum', 'catalunya'], ['polic', 'chief', 'sent', 'stop', 'catalan', 'referendum,', 'fascist', 'support', 'tejero', 'coup'], ['@jaromil', 'ipf', 'block', 'catalunya', 'due', 'referendum,', 'necessari', 'collabor', 'main', 'providers.', 'mani', 'block', 'websites.'], ['this', 'manipul', 'spanish', 'knew', 'problem', 'catalunya', 'pp', 'el', 'care', 'referendum', 'valid', 'let', 'vote.ignor', 'el', 'pai']]\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat term dictionary dari korpus kita, dimana setiap kata unik akan diberikan sebuah index\n",
    "dictionary = Dictionary(tweets)\n",
    "\n",
    "# buang term yang:\n",
    "# 1. muncul di kurang dari 2 dokumen\n",
    "# 2. muncul di lebih dari 0.9*(total_dok) dokumen\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.9)\n",
    "\n",
    "# ubah dictionary menjadi object bag-of-words reference\n",
    "# ingat bahwa dalama LDA, dokumen diasumsikan dengan bag-of-words model\n",
    "corpus = [dictionary.doc2bow(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 1)], [(0, 1), (2, 1), (3, 2)], [(4, 1)], [(0, 1), (5, 1), (6, 1), (7, 1), (8, 1)], [(5, 1), (6, 1), (7, 1)], [(0, 1), (9, 1), (10, 1)], [(0, 1), (7, 1), (11, 1), (12, 1)], [(0, 1), (5, 1), (7, 1), (8, 1), (13, 1), (14, 1)], [(5, 1), (7, 1), (10, 1), (14, 1), (15, 1), (16, 1)], [(5, 1), (7, 1), (9, 1)], [(0, 1)], [(0, 1)], [(5, 1), (7, 1), (11, 1), (12, 1), (14, 1), (17, 1), (18, 1)], [(1, 1), (3, 1), (5, 1), (7, 1), (14, 1)], [(0, 1)], [(5, 1), (7, 2), (14, 2)], [(0, 1), (5, 1), (7, 1), (19, 1)], [(0, 1), (4, 1)], [(20, 1), (21, 1)], [(20, 1), (21, 1), (22, 1), (23, 1)], [(13, 1), (20, 1), (24, 1)], [(25, 1), (26, 1), (27, 1)], [(20, 1), (21, 1), (23, 1)], [(20, 1), (21, 1), (26, 1)], [(20, 1), (28, 1)], [(20, 1), (21, 1), (29, 1)], [(20, 1), (21, 1), (30, 1), (31, 1), (32, 1), (33, 1)], [(20, 1), (21, 1), (30, 1), (31, 1)], [(3, 1), (18, 1), (20, 1), (21, 1)], [(19, 1), (20, 1), (21, 2), (33, 1), (34, 1)], [(20, 1), (21, 1), (22, 1), (29, 1), (32, 1), (35, 1)], [(10, 1), (20, 1), (21, 1), (25, 1), (26, 1), (28, 1), (34, 1)], [(36, 1), (37, 1), (38, 1), (39, 1), (40, 1)], [(37, 1), (39, 2), (41, 1)], [(37, 1), (41, 1), (42, 1)], [(40, 1), (43, 1)], [(2, 1), (27, 1), (37, 1), (41, 1), (44, 1)], [(10, 1), (36, 1), (41, 1), (45, 1)], [(37, 1), (41, 1), (45, 1), (46, 1)], [(2, 1), (41, 1), (46, 1)], [(37, 1), (41, 1), (47, 1)], [(17, 1), (36, 1), (43, 1), (48, 1)], [(36, 1), (41, 1), (49, 1), (50, 1)], [(24, 1), (35, 1), (37, 1), (41, 1)], [(15, 1), (36, 1), (41, 1), (48, 1)], [(41, 1), (42, 1), (50, 1), (51, 1)], [(37, 1), (41, 1)], [(36, 1), (38, 1), (39, 1), (44, 1), (51, 1)], [(16, 1), (37, 1), (38, 1), (47, 1), (49, 2)], [(37, 1), (41, 1), (50, 1)]]\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LDA\n",
    "lda = ldamodel.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, random_state=42, iterations=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic number: 0\n",
      "samsung 0.1279757\n",
      "galaxi 0.09727413\n",
      "note 0.081398584\n",
      "iphon 0.06606686\n",
      "referendum 0.052219264\n",
      "time 0.034927897\n",
      "still 0.034894504\n",
      "even 0.03485522\n",
      "lost 0.034776494\n",
      "tomorrow 0.03473522\n",
      "topic number: 1\n",
      "iphon 0.101325\n",
      "catalunya 0.09613534\n",
      "referendum 0.08747995\n",
      "support 0.046080384\n",
      "champion 0.032856427\n",
      "leagu 0.03263743\n",
      "referendum, 0.032056753\n",
      "block 0.03204547\n",
      "watch 0.032028172\n",
      "year 0.03198766\n",
      "topic number: 2\n",
      "leagu 0.09808679\n",
      "champion 0.09804178\n",
      "referendum 0.051687572\n",
      "catalan 0.051005125\n",
      "chelsea 0.05093845\n",
      "samsung 0.035849955\n",
      "year 0.035549145\n",
      "galaxi 0.03548846\n",
      "spanish 0.0354884\n",
      "atletico 0.035458796\n",
      "topic number: 3\n",
      "leagu 0.09576264\n",
      "champion 0.095440865\n",
      "catalunya 0.05143575\n",
      "premier 0.05020862\n",
      "kane 0.050193615\n",
      "harri 0.05016487\n",
      "viva 0.049813174\n",
      "iphon 0.030219596\n",
      "referendum 0.029424462\n",
      "catalan 0.028665666\n"
     ]
    }
   ],
   "source": [
    "# tampilkan topic matrix\n",
    "topics_matrix = lda.show_topics(formatted=False)\n",
    "\n",
    "for topic_no, topic_words in topics_matrix:\n",
    "\n",
    "    print ('topic number: {}'.format(topic_no))\n",
    "\n",
    "    # default: top-10 kata yang paling tinggi probabilitasnya\n",
    "    for word, prob in topic_words:\n",
    "        print (word, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic # 01</th>\n",
       "      <th>Topic # 02</th>\n",
       "      <th>Topic # 03</th>\n",
       "      <th>Topic # 04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samsung</td>\n",
       "      <td>iphon</td>\n",
       "      <td>leagu</td>\n",
       "      <td>leagu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>galaxi</td>\n",
       "      <td>catalunya</td>\n",
       "      <td>champion</td>\n",
       "      <td>champion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>note</td>\n",
       "      <td>referendum</td>\n",
       "      <td>referendum</td>\n",
       "      <td>catalunya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphon</td>\n",
       "      <td>support</td>\n",
       "      <td>catalan</td>\n",
       "      <td>premier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referendum</td>\n",
       "      <td>champion</td>\n",
       "      <td>chelsea</td>\n",
       "      <td>kane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time</td>\n",
       "      <td>leagu</td>\n",
       "      <td>samsung</td>\n",
       "      <td>harri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>still</td>\n",
       "      <td>referendum,</td>\n",
       "      <td>year</td>\n",
       "      <td>viva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>even</td>\n",
       "      <td>block</td>\n",
       "      <td>galaxi</td>\n",
       "      <td>iphon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lost</td>\n",
       "      <td>watch</td>\n",
       "      <td>spanish</td>\n",
       "      <td>referendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>year</td>\n",
       "      <td>atletico</td>\n",
       "      <td>catalan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic # 01   Topic # 02  Topic # 03  Topic # 04\n",
       "0     samsung        iphon       leagu       leagu\n",
       "1      galaxi    catalunya    champion    champion\n",
       "2        note   referendum  referendum   catalunya\n",
       "3       iphon      support     catalan     premier\n",
       "4  referendum     champion     chelsea        kane\n",
       "5        time        leagu     samsung       harri\n",
       "6       still  referendum,        year        viva\n",
       "7        even        block      galaxi       iphon\n",
       "8        lost        watch     spanish  referendum\n",
       "9    tomorrow         year    atletico     catalan"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lda_topics(model):\n",
    "    word_dict = {};\n",
    "    for i in range(num_topics):\n",
    "        words = model.show_topic(i, topn = 10);\n",
    "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = [i[0] for i in words];\n",
    "    return pd.DataFrame(word_dict);\n",
    "\n",
    "get_lda_topics(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 2, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 2, 3, 1, 3, 3, 3, 2, 3, 2, 2, 3, 2, 0, 3, 2, 0, 0, 2, 0, 0, 1, 1, 0, 3, 3, 2, 3, 3, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# bentuk terlebih dahulu vektor dokumen/tweet\n",
    "# vektor tweet/dokumen = vektor probabilitas terhadap masing-masing topik\n",
    "tweet_vectors = []\n",
    "for tweet in tweets:\n",
    "    probs = [prob for (_,prob) in lda.get_document_topics(dictionary.doc2bow(tweet))]\n",
    "    tweet_vectors.append(probs)\n",
    "tweet_vectors = np.array(tweet_vectors)\n",
    "\n",
    "# kita set banyaknya cluster = banyaknya topik\n",
    "num_clusters = num_topics\n",
    "\n",
    "# gunakan algoritma K-Means, dan lakukan clustering !\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(tweet_vectors)\n",
    "\n",
    "# jika kita ingin melihat indeks cluster untuk setiap tweet/dokumen\n",
    "clusters = km.labels_.tolist()\n",
    "\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06440544 0.80826455 0.06419452 0.06313552]\n",
      " [0.05095474 0.8467538  0.05208589 0.05020561]\n",
      " [0.13270642 0.12515919 0.1251967  0.61693764]\n",
      " [0.8734298  0.04273069 0.04197443 0.04186513]\n",
      " [0.8113674  0.06282119 0.06327626 0.06253513]\n",
      " [0.06514984 0.8065115  0.06546419 0.06287444]\n",
      " [0.84794307 0.05154614 0.05021422 0.05029653]\n",
      " [0.89169335 0.03645258 0.03599778 0.03585628]\n",
      " [0.8909706  0.03657869 0.03669829 0.03575238]\n",
      " [0.48663488 0.06704279 0.38368675 0.06263558]\n",
      " [0.13245341 0.61535233 0.12509492 0.12709935]\n",
      " [0.1322999  0.61550957 0.1250948  0.12709571]\n",
      " [0.9053029  0.03132921 0.03208936 0.03127854]\n",
      " [0.4460133  0.04428927 0.46796685 0.0417306 ]\n",
      " [0.13234101 0.6154674  0.12509483 0.12709673]\n",
      " [0.87418264 0.04184069 0.04229535 0.04168131]\n",
      " [0.5289394  0.3649977  0.05079589 0.05526695]\n",
      " [0.7362744  0.08936641 0.08347072 0.09088844]\n",
      " [0.08378638 0.08517474 0.09240819 0.73863065]\n",
      " [0.05014256 0.05129726 0.8467969  0.05176331]\n",
      " [0.45691472 0.06338743 0.06600412 0.41369376]\n",
      " [0.06254972 0.0638527  0.81102526 0.06257233]\n",
      " [0.06271564 0.06331073 0.8083422  0.06563143]\n",
      " [0.06271096 0.06330597 0.8084016  0.06558148]\n",
      " [0.08381601 0.08425611 0.09031121 0.74161667]\n",
      " [0.06285972 0.40447658 0.46437448 0.06828923]\n",
      " [0.03578537 0.03619837 0.03659125 0.891425  ]\n",
      " [0.05013646 0.05050238 0.05198604 0.8473751 ]\n",
      " [0.05097797 0.05129598 0.84595984 0.05176619]\n",
      " [0.03578809 0.03632055 0.0374565  0.89043486]\n",
      " [0.03585566 0.55004776 0.03856391 0.37553272]\n",
      " [0.03173814 0.03186016 0.90355533 0.03284641]\n",
      " [0.04199451 0.4313534  0.04310829 0.48354384]\n",
      " [0.05064658 0.84744716 0.05045831 0.05144793]\n",
      " [0.06363941 0.80765224 0.06516641 0.06354196]\n",
      " [0.08340137 0.08339419 0.08561652 0.74758786]\n",
      " [0.04238151 0.8729306  0.04261526 0.04207261]\n",
      " [0.24311447 0.6507769  0.05475503 0.05135354]\n",
      " [0.6899921  0.20760112 0.0507948  0.05161205]\n",
      " [0.8016722  0.07120065 0.06397507 0.06315206]\n",
      " [0.06362726 0.80956537 0.06328531 0.06352206]\n",
      " [0.05095644 0.05039734 0.8469966  0.05164963]\n",
      " [0.05096641 0.05575661 0.8425257  0.05075127]\n",
      " [0.0525265  0.3717162  0.05094754 0.5248098 ]\n",
      " [0.0519494  0.05212135 0.8451793  0.05074988]\n",
      " [0.0508876  0.05454521 0.8441547  0.05041248]\n",
      " [0.08575655 0.7437794  0.08498218 0.08548188]\n",
      " [0.04181897 0.8713904  0.04385845 0.04293218]\n",
      " [0.03623468 0.89146    0.03611198 0.03619331]\n",
      " [0.06364458 0.8044672  0.06834105 0.06354716]]\n"
     ]
    }
   ],
   "source": [
    "print(tweet_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0 words:\n",
      "iphon,catalunya\n",
      "cluster 1 words:\n",
      "leagu,champion\n",
      "cluster 2 words:\n",
      "samsung,galaxi\n",
      "cluster 3 words:\n",
      "leagu,champion\n"
     ]
    }
   ],
   "source": [
    "# untuk setiap cluster center, kita sort argumen/index berdasarkan nilai probabilitasnya\n",
    "# karena index/argumen adalah id topik.\n",
    "#\n",
    "# jadi, secara intuisi, ini adalah cara untuk mencari topik major yang dibicarakan di sebuah cluster\n",
    "# nantinya, wakil kata cluster akan diambil dari 2 topik major di setiap cluster\n",
    "#\n",
    "# ::-1 artinya reverse list\n",
    "\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "cluster_names = {}\n",
    "for i in range(num_clusters):\n",
    "    print (\"cluster %d words:\" % i)\n",
    "    \n",
    "    # ambil 2 topik major untuk setiap cluster\n",
    "    topic_words = []\n",
    "    for ind in order_centroids[i, :1]:\n",
    "        topic_words += [dictionary.get(word_id) for (word_id, prob) in lda.get_topic_terms(ind, topn=2)]\n",
    "    \n",
    "    cluster_names[i] = ','.join(topic_words)\n",
    "\n",
    "    print (cluster_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.80618477 0.06746034 0.06336243 0.06299248]\n",
      " [0.05259623 0.8414018  0.05436617 0.0516358 ]\n",
      " [0.6244938  0.12520477 0.1251576  0.12514387]\n",
      " [0.04627742 0.04668002 0.8641156  0.04292697]\n",
      " [0.06562262 0.31141058 0.5585325  0.06443434]\n",
      " [0.1388234  0.06630667 0.06642415 0.72844577]\n",
      " [0.0520206  0.84520745 0.05082975 0.0519422 ]\n",
      " [0.03801076 0.41396883 0.51126695 0.03675345]\n",
      " [0.03630483 0.0404459  0.03735645 0.88589287]\n",
      " [0.06312862 0.42790595 0.06880143 0.44016403]\n",
      " [0.61494297 0.13042061 0.12802364 0.12661281]\n",
      " [0.614936   0.13042894 0.12802224 0.12661284]\n",
      " [0.03177203 0.3859676  0.0318071  0.5504533 ]\n",
      " [0.0421292  0.87191015 0.04315391 0.04280671]\n",
      " [0.6150019  0.13036804 0.1280188  0.12661128]\n",
      " [0.04186383 0.87270033 0.04261672 0.04281909]\n",
      " [0.05220068 0.8448282  0.05203149 0.05093963]\n",
      " [0.747111   0.08481783 0.08422901 0.08384211]\n",
      " [0.08335732 0.08499608 0.74552023 0.08612632]\n",
      " [0.05003056 0.05209616 0.8471128  0.05076052]\n",
      " [0.06254663 0.06308518 0.8091954  0.06517283]\n",
      " [0.06367312 0.06257778 0.06304482 0.8107043 ]\n",
      " [0.06252432 0.06330173 0.8103664  0.06380752]\n",
      " [0.06254289 0.06334216 0.8039389  0.07017602]\n",
      " [0.08340319 0.72861725 0.09694387 0.09103564]\n",
      " [0.06253881 0.06629551 0.8073569  0.06380881]\n",
      " [0.03574305 0.03663531 0.8904729  0.0371487 ]\n",
      " [0.0500389  0.05050942 0.8460289  0.05342273]\n",
      " [0.05003317 0.05161805 0.47710866 0.4212401 ]\n",
      " [0.03573664 0.03669556 0.8908047  0.03676308]\n",
      " [0.03574358 0.6439045  0.28335655 0.03699535]\n",
      " [0.03127029 0.03204283 0.0333346  0.90335226]\n",
      " [0.8729491  0.04171298 0.04274556 0.04259238]\n",
      " [0.8470799  0.05016458 0.05239091 0.05036466]\n",
      " [0.8110994  0.06275365 0.06304472 0.06310225]\n",
      " [0.08927506 0.08351929 0.08344728 0.7437584 ]\n",
      " [0.872102   0.04276635 0.04248168 0.04264993]\n",
      " [0.47884426 0.05025673 0.05015594 0.4207431 ]\n",
      " [0.8463754  0.05175708 0.05034781 0.05151971]\n",
      " [0.80245584 0.07035955 0.06423603 0.06294861]\n",
      " [0.8092809  0.06278187 0.06481081 0.06312644]\n",
      " [0.84714955 0.05008347 0.05005035 0.05271661]\n",
      " [0.84706587 0.05017443 0.05234046 0.05041926]\n",
      " [0.34210438 0.05249745 0.05205011 0.55334806]\n",
      " [0.8480881  0.05017826 0.05010782 0.05162587]\n",
      " [0.849493   0.05016506 0.05010088 0.05024105]\n",
      " [0.7471417  0.08381509 0.08446056 0.08458261]\n",
      " [0.87394714 0.04170649 0.04254089 0.04180546]\n",
      " [0.04000821 0.03577353 0.88777864 0.03643961]\n",
      " [0.81111836 0.06274505 0.06303895 0.06309763]]\n"
     ]
    }
   ],
   "source": [
    "print(tweet_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So it's the Kardashians' 10 yr anniversary, an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iPhone is 10 years old. Apple Watch is 2 years...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you can't save 10% of what you make, you ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's that time of year! My iPhone 8 vs. Samsun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selling Yeezys and a Samsung Galaxy S8 is anyo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iPhone 6 16gb Spacegray 10,200 pesos only! Com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I swear even if my iPhone dressed up as a clow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iPhone 8's A11 Bionic chip lost against the Sa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Confused should I post a dedicated camera revi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You guys i have a used iphone6&amp; Samsung galaxy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can my mom say when the devil gives you Sa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>If only Cassie had an iPhone 10 that she could...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>infamous Samsung galaxy note 7 is still banned...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So, I have a really dumb phone. It's a Samsung...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"Bro my Windows 10 deluxe 9000 brick trashcan ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Samsung Galaxy Note 8 camera: Blurring the lin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IPhone x looks a lot like Samsung galaxy s10 plus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Congratulations. Any news on iPhone 10.3.1 jai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Messi arguably has the greatest performance in...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Im not gonna boo Gini tomorrow, he was always ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Grayson backtracking, lost it for me, Bruce di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Chelsea just found out that city is not atleti...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Delph is an idiot for leaving Villa. Relegatio...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Chelsea have taken 1 point out of a possible 6...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Zinedine Zidane: \"Give me lord fellaini and 10...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>This DJ just played the Champions League anthe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Harry Kane is currently joint top scorer in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Harry Kane one of a few who deserves world-cla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Christensen: Facing the strikers in the Bundes...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>It's been a while since Premier League clubs h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Good Luck Arsenal On your Europa League Game, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Chelsea's display the best of the English club...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The brilliant Scottish crew supporting the Cat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>As a Brexit supporter I support the Catalunya ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>IT'S OFFICIALLY REFERENDUM DAY BABY AWOOOOO (W...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Derry's Walls have turned Yellow &amp; Red in soli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Watching Madrid force their police into Catalu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Catalan referendum in full flow in Barcelona ....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Patriotic fervour in Barcelona ahead of refere...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Tomorrow will be the #indyref referendum in #C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Controversial referendum is due to be staged o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Last poll on Catalan independence referendum.8...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Catalan judges sue Spanish govt. for blocking ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Some more thoughts on what we were trying to g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>WikiLeaks mirror of censored Catalan governmen...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Chaos In Catalonia: Spanish Officials Scramble...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Taste the atmosfere of the referendum in Catal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Police chief sent to stop Catalan Referendum, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>@jaromil All IPFS blocked in Catalunya due to ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>This's manipulation 92% Spanish knew d problem...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  1\n",
       "0   So it's the Kardashians' 10 yr anniversary, an...  2\n",
       "1   iPhone is 10 years old. Apple Watch is 2 years...  2\n",
       "2   If you can't save 10% of what you make, you ar...  0\n",
       "3   It's that time of year! My iPhone 8 vs. Samsun...  1\n",
       "4   Selling Yeezys and a Samsung Galaxy S8 is anyo...  1\n",
       "5   iPhone 6 16gb Spacegray 10,200 pesos only! Com...  2\n",
       "6   I swear even if my iPhone dressed up as a clow...  1\n",
       "7   iPhone 8's A11 Bionic chip lost against the Sa...  1\n",
       "8   Confused should I post a dedicated camera revi...  1\n",
       "9   You guys i have a used iphone6& Samsung galaxy...  1\n",
       "10  How can my mom say when the devil gives you Sa...  2\n",
       "11  If only Cassie had an iPhone 10 that she could...  2\n",
       "12  infamous Samsung galaxy note 7 is still banned...  1\n",
       "13  So, I have a really dumb phone. It's a Samsung...  1\n",
       "14  \"Bro my Windows 10 deluxe 9000 brick trashcan ...  2\n",
       "15  Samsung Galaxy Note 8 camera: Blurring the lin...  1\n",
       "16  IPhone x looks a lot like Samsung galaxy s10 plus  1\n",
       "17  Congratulations. Any news on iPhone 10.3.1 jai...  1\n",
       "18  Messi arguably has the greatest performance in...  3\n",
       "19  Im not gonna boo Gini tomorrow, he was always ...  3\n",
       "20  Grayson backtracking, lost it for me, Bruce di...  1\n",
       "21  Chelsea just found out that city is not atleti...  3\n",
       "22  Delph is an idiot for leaving Villa. Relegatio...  3\n",
       "23  Chelsea have taken 1 point out of a possible 6...  3\n",
       "24  Zinedine Zidane: \"Give me lord fellaini and 10...  0\n",
       "25  This DJ just played the Champions League anthe...  3\n",
       "26  Harry Kane is currently joint top scorer in th...  0\n",
       "27  Harry Kane one of a few who deserves world-cla...  0\n",
       "28  Christensen: Facing the strikers in the Bundes...  3\n",
       "29  It's been a while since Premier League clubs h...  0\n",
       "30  Good Luck Arsenal On your Europa League Game, ...  2\n",
       "31  Chelsea's display the best of the English club...  3\n",
       "32  The brilliant Scottish crew supporting the Cat...  0\n",
       "33  As a Brexit supporter I support the Catalunya ...  2\n",
       "34  IT'S OFFICIALLY REFERENDUM DAY BABY AWOOOOO (W...  2\n",
       "35  Derry's Walls have turned Yellow & Red in soli...  0\n",
       "36  Watching Madrid force their police into Catalu...  2\n",
       "37  Catalan referendum in full flow in Barcelona ....  2\n",
       "38  Patriotic fervour in Barcelona ahead of refere...  1\n",
       "39  Tomorrow will be the #indyref referendum in #C...  1\n",
       "40  Controversial referendum is due to be staged o...  2\n",
       "41  Last poll on Catalan independence referendum.8...  3\n",
       "42  Catalan judges sue Spanish govt. for blocking ...  3\n",
       "43  Some more thoughts on what we were trying to g...  0\n",
       "44  WikiLeaks mirror of censored Catalan governmen...  3\n",
       "45  Chaos In Catalonia: Spanish Officials Scramble...  3\n",
       "46  Taste the atmosfere of the referendum in Catal...  2\n",
       "47  Police chief sent to stop Catalan Referendum, ...  2\n",
       "48  @jaromil All IPFS blocked in Catalunya due to ...  2\n",
       "49  This's manipulation 92% Spanish knew d problem...  2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.stack((tweets_label, clusters), axis=1)\n",
    "\n",
    "# print(arr)\n",
    "\n",
    "df = pd.DataFrame(arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the LSA\n",
    "lsa = lsimodel.LsiModel(corpus, num_topics=num_topics, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic number: 0\n",
      "samsung 0.5694504832291907\n",
      "galaxi 0.46000822404892383\n",
      "note 0.3697781992228932\n",
      "iphon 0.3058372721112972\n",
      "leagu 0.2521851117614065\n",
      "champion 0.2416746513195237\n",
      "time 0.11026118624489052\n",
      "year 0.10798110206520731\n",
      "full 0.09514996018605527\n",
      "still 0.08925825364615346\n",
      "topic number: 1\n",
      "leagu -0.6161956881090622\n",
      "champion -0.5871219620209108\n",
      "samsung 0.24933798093875167\n",
      "galaxi 0.19947051924854084\n",
      "note 0.16167142423147549\n",
      "premier -0.1276878308319734\n",
      "club -0.12614770428359942\n",
      "iphon 0.12558737335257536\n",
      "league. -0.10866317305149653\n",
      "chelsea -0.10417389455442691\n",
      "topic number: 2\n",
      "referendum 0.6705314663999484\n",
      "catalunya 0.5553513130271784\n",
      "catalan 0.2239633781177419\n",
      "support 0.21550103319547442\n",
      "spanish 0.14628019942545026\n",
      "block 0.14075350826826646\n",
      "referendum, 0.12437357871861839\n",
      "barcelona 0.10199862319150926\n",
      "watch 0.10103118357056613\n",
      "due 0.10081745606983565\n",
      "topic number: 3\n",
      "iphon 0.869873583097004\n",
      "note -0.2824839483472342\n",
      "samsung -0.1962560506204438\n",
      "year 0.18683490082167384\n",
      "galaxi -0.16177379814925366\n",
      "watch 0.12435525204539023\n",
      "so, 0.11247485407850921\n",
      "new 0.0760759802691416\n",
      "main -0.06946806186966527\n",
      "time 0.06873268455652229\n"
     ]
    }
   ],
   "source": [
    "# tampilkan topic matrix\n",
    "topics_matrix_lsa = lsa.show_topics(formatted=False)\n",
    "\n",
    "for topic_no, topic_words in topics_matrix_lsa:\n",
    "\n",
    "    print ('topic number: {}'.format(topic_no))\n",
    "\n",
    "    # default: top-10 kata yang paling tinggi probabilitasnya\n",
    "    for word, prob in topic_words:\n",
    "        print (word, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_topics() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-2e38c75e3083>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtweet_vectors_lsa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprob\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtweet_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtweet_vectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_topics() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# bentuk terlebih dahulu vektor dokumen/tweet\n",
    "# vektor tweet/dokumen = vektor probabilitas terhadap masing-masing topik\n",
    "tweet_vectors_lsa = []\n",
    "for tweet in tweets:\n",
    "    probs = [prob for (_,prob) in lsa.get_topics(dictionary.doc2bow(tweet))]\n",
    "    tweet_vectors.append(probs)\n",
    "tweet_vectors = np.array(tweet_vectors)\n",
    "\n",
    "# kita set banyaknya cluster = banyaknya topik\n",
    "num_clusters_lsa = num_topics\n",
    "\n",
    "# gunakan algoritma K-Means, dan lakukan clustering !\n",
    "km = KMeans(n_clusters=num_clusters_lsa)\n",
    "km.fit(tweet_vectors_lsa)\n",
    "\n",
    "# jika kita ingin melihat indeks cluster untuk setiap tweet/dokumen\n",
    "clusters_lsa = km.labels_.tolist()\n",
    "\n",
    "print(clusters_lsa)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "383ff6ec061058c8c67bbbe8229d15dd1c5eb70693263c63cde4fbc9e65720c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
